## 웹 크롤러 사용사례

#### 검색 엔진 인덱싱
* 웹페이지를 모아 검색엔진을 위한 로컬 인덱스를 생성한다.

#### 웹 아카이빙
* 나중에 사용할 목적으로 장기보관 하기위해 웹에서 정보를 모으는 절차

#### 웹마이닝
* 인터넷에서 유용한 지식을 도출

#### 웹 모니터링
* 저작권, 상표권이 침해되는 사례를 모니터링

<br>

## 웹 크롤러 설계 시 주의해야할 속성
* 웹은 거대하니 병행성을 활용해 크롤링 한다.
* 완벽하지 않은 웹에 대해 대응해야 한다.
  * ex) 잘못 작성된 HTML, 악성코드가 붙은 링크 등
* 수집대상에 짧은시간동안 너무 많은 요청을 보내지 말아야 한다.
* 확장성
  * 새로운 형태의 콘텐츠를 지원하기 쉬워야 한다.

<br>
 
## 웹 크롤러 설계안

* 시작 URL 집합
  * 크롤링을 시작하는 출발점
  * URL공간을 주제별로 세분화 하고 각각에 다른 시작 URL을 설정

* 미수집 URL 저장소
  * 크롤링 상태를 다운로드할 URL / 다운로드된 URL로 나눠 관리한다.
  * 다운로드할 URL == 미수집 URL 저장소
  * FIFO QUEUE
 
* HTML 다운로더
  * 인터넷에서 웹페이지를 다운로드하는 컴포넌트
  * 미수집 URL 큐에서 꺼내 씀

* 도메인 이름 변환기
  * URL -> IP 주소 변환

* 콘텐츠 파서
  * 웹 페이지를 다운로드하면 파싱과 검증 절차를 거쳐야 한다.
  * 크롤링 서버가 아닌 독립된 컴포넌트로 생성

* 중복 콘텐츠 인가?
  * 연구결과 웹의 29%가량은 중복이다.
  * 웹페이지의 해시값을 비교한다.

* 콘텐츠 저장소
  * HTML문서를 보관하는 시스템
  * 디스크에 저장하고 적절한 캐시전략을 사용한다.

* URL 추출기
  * HTML 페이지를 파싱하여 링크들을 추출하는 역할

* URL필터
  * 크롤링 대상에서 제외하는 역할

* 이미 방문한 URL?
  * 블룸필터 / 해시테이블을 사용하여 중복작업 제거

* URL 저장소
  * 이미 방문한 URL을 보관하는 저장소

<br>

## 상세설계
* BFS 알고리즘
* 미수집 URL 저장소
  * 예의
  * 우선순위
  * 신선도
  * 미수집 URL 저장소를 위한 지속성 저장장치
* HTML 다운로더
  * 성능 최적화
    * 분산크롤링
    * 도메인 이름변환결과 캐시
    * 지역별 분산
    * 짧은 타임아웃
  * 안정성
    * 안정해시
    * 크롤링 상태 및 수집데이터 저장
    * 예외 처리
    * 데이터 검증
  * 확장성
  * 문제있는 콘텐츠 감지 및 회피 전략
    * 중복콘텐츠
    * 무한루프
    * 데이터 노이즈




